{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn import decomposition\n",
    "from sklearn import feature_selection\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import neighbors\n",
    "from sklearn.externals import joblib\n",
    "from rfpimp import *\n",
    "\n",
    "#import seaborn as sns\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "model_path = os.path.join('./models_trained')\n",
    "if not os.path.isdir(model_path):\n",
    "    os.makedirs(model_path)\n",
    "\n",
    "import pandas as pd\n",
    "%matplotlib inline    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#font = {'family'        : 'sans-serif',\n",
    "#        'sans-serif'    : ['Computer Modern Sans serif'],\n",
    "#        'weight'        : 'regular',\n",
    "#        'size'          : 12}\n",
    "\n",
    "text = {'usetex'        : False}\n",
    "\n",
    "#plt.rc('font', **font)\n",
    "plt.rc('text', **text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bos0109/.local/lib/python3.6/site-packages/psycopg2/__init__.py:144: UserWarning: The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use \"pip install psycopg2-binary\" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.\n",
      "  \"\"\")\n"
     ]
    }
   ],
   "source": [
    "#CONNECTION = 'postgresql://jarvis:Bessel0@172.18.122.4:5432/resimulation_docker'\n",
    "CONNECTION = 'postgresql://jarvis:Bessel0@toritos:5432/resimu_docker'\n",
    "engine = create_engine(CONNECTION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "store = pd.HDFStore('/mnt/is0/bos0109/Devel/table_store.h5')\n",
    "store.open()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.io.pytables.HDFStore'>\n",
      "File path: /mnt/is0/bos0109/Devel/table_store.h5\n",
      "/bogus_b              frame        (shape->[2565918,75])\n",
      "/bogus_h              frame        (shape->[6651370,75])\n",
      "/bogus_z              frame        (shape->[4084078,75])\n",
      "/cx_hot               frame        (shape->[2143228,5]) \n",
      "/cx_ois               frame        (shape->[2308776,5]) \n",
      "/cx_sps               frame        (shape->[2975174,6]) \n",
      "/cx_zps               frame        (shape->[2695203,5]) \n",
      "/dt_hot               frame        (shape->[8957959,51])\n",
      "/dt_ois               frame        (shape->[5073964,51])\n",
      "/dt_scr               frame        (shape->[6676671,8]) \n",
      "/dt_sps               frame        (shape->[6085667,40])\n",
      "/dt_zps               frame        (shape->[7098650,51])\n",
      "/simulated            frame        (shape->[4630520,26])\n",
      "/und_b                frame        (shape->[2321744,5]) \n",
      "/und_h                frame        (shape->[1199582,5]) \n",
      "/und_s                frame        (shape->[1601099,5]) \n",
      "/und_sc               frame        (shape->[1684363,5]) \n",
      "/und_z                frame        (shape->[2517584,5]) \n"
     ]
    }
   ],
   "source": [
    "print(store.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    dt_zps = store['dt_zps']\n",
    "except:\n",
    "    dt_zps = pd.merge(pd.read_sql_table('Detected', engine),\n",
    "                  pd.read_sql_query(\"\"\"SELECT \n",
    "                                        D.id,\n",
    "                                        S.app_mag as sim_mag,\n",
    "                                        S.r_scales as r_scales,\n",
    "                                        S.gx_mag as gx_mag,\n",
    "                                        S.id as sim_id \n",
    "                                    FROM \"Detected\" D\n",
    "                                        LEFT JOIN \"Images\" I\n",
    "                                            ON D.image_id=I.id\n",
    "                                        LEFT JOIN \"Reals\" R\n",
    "                                            ON D.id=R.detected_id\n",
    "                                        LEFT JOIN \"Simulated\" S\n",
    "                                            ON S.id=R.simulated_id\"\"\", engine),\n",
    "                                      on='id', suffixes=('',''))\n",
    "    store['dt_zps'] = dt_zps\n",
    "    store.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    dt_sps = store['dt_sps']\n",
    "except:\n",
    "    dt_sps = pd.merge(pd.read_sql_table('SDetected', engine),\n",
    "                  pd.read_sql_query(\"\"\"SELECT \n",
    "                                        D.id,\n",
    "                                        S.app_mag as sim_mag,\n",
    "                                        S.r_scales as r_scales,\n",
    "                                        S.gx_mag as gx_mag,\n",
    "                                        S.id as sim_id \n",
    "                                    FROM \"SDetected\" D\n",
    "                                        LEFT JOIN \"SReals\" R\n",
    "                                            ON D.id=R.detected_id\n",
    "                                        LEFT JOIN \"Simulated\" S\n",
    "                                            ON S.id=R.simulated_id\"\"\", engine),\n",
    "                                      on='id', suffixes=('',''))\n",
    "    store['dt_sps'] = dt_sps\n",
    "    store.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    dt_ois = store['dt_ois']\n",
    "except:\n",
    "    dt_ois = pd.merge(pd.read_sql_table('DetectedOIS', engine),\n",
    "                  pd.read_sql_query(\"\"\"SELECT \n",
    "                                        D.id,\n",
    "                                        S.app_mag as sim_mag,\n",
    "                                        S.r_scales as r_scales,\n",
    "                                        S.gx_mag as gx_mag,\n",
    "                                        S.id as sim_id \n",
    "                                    FROM \"DetectedOIS\" D\n",
    "                                        LEFT JOIN \"RealsOIS\" R\n",
    "                                            ON D.id=R.detected_id\n",
    "                                        LEFT JOIN \"Simulated\" S\n",
    "                                            ON S.id=R.simulated_id\"\"\", engine),\n",
    "                                      on='id', suffixes=('',''))\n",
    "    store['dt_ois'] = dt_ois\n",
    "    store.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    dt_hot = store['dt_hot']\n",
    "except:\n",
    "    dt_hot = pd.merge(pd.read_sql_table('DetectedHOT', engine),\n",
    "                  pd.read_sql_query(\"\"\"SELECT \n",
    "                                        D.id,\n",
    "                                        S.app_mag as sim_mag,\n",
    "                                        S.r_scales as r_scales,\n",
    "                                        S.gx_mag as gx_mag, \n",
    "                                        S.id as sim_id \n",
    "                                    FROM \"DetectedHOT\" D\n",
    "                                        LEFT JOIN \"RealsHOT\" R\n",
    "                                            ON D.id=R.detected_id\n",
    "                                        LEFT JOIN \"Simulated\" S\n",
    "                                            ON S.id=R.simulated_id\"\"\", engine),\n",
    "                                      on='id', suffixes=('',''))\n",
    "    store['dt_hot'] = dt_hot\n",
    "    store.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "store.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dt_ois.IS_REAL = dt_ois.IS_REAL.astype('bool').astype(int)\n",
    "dt_zps.IS_REAL = dt_zps.IS_REAL.astype('bool').astype(int)\n",
    "dt_sps.IS_REAL = dt_sps.IS_REAL.astype('bool').astype(int)\n",
    "dt_hot.IS_REAL = dt_hot.IS_REAL.astype('bool').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We're going to be calculating memory usage a lot,\n",
    "# so we'll create a function to save us some time!\n",
    "\n",
    "def mem_usage(pandas_obj):\n",
    "    if isinstance(pandas_obj,pd.DataFrame):\n",
    "        usage_b = pandas_obj.memory_usage(deep=True).sum()\n",
    "    else: # we assume if not a df it's a series\n",
    "        usage_b = pandas_obj.memory_usage(deep=True)\n",
    "    usage_mb = usage_b / 1024 ** 2 # convert bytes to megabytes\n",
    "    return \"{:03.2f} MB\".format(usage_mb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def optimize_df(df):\n",
    "    df_int = df.select_dtypes(include=['int'])\n",
    "    converted_int = df_int.apply(pd.to_numeric, downcast='unsigned')\n",
    "\n",
    "    print(mem_usage(df_int))\n",
    "    print(mem_usage(converted_int))\n",
    "\n",
    "    compare_ints = pd.concat([df_int.dtypes,converted_int.dtypes],axis=1)\n",
    "    compare_ints.columns = ['before','after']\n",
    "    compare_ints.apply(pd.Series.value_counts)\n",
    "    \n",
    "    df_float = df.select_dtypes(include=['float'])\n",
    "    converted_float = df_float.apply(pd.to_numeric,downcast='float')\n",
    "\n",
    "    print(mem_usage(df_float))\n",
    "    print(mem_usage(converted_float))\n",
    "\n",
    "    compare_floats = pd.concat([df_float.dtypes,converted_float.dtypes],axis=1)\n",
    "    compare_floats.columns = ['before','after']\n",
    "    compare_floats.apply(pd.Series.value_counts)\n",
    "    \n",
    "    optimized_df = df.copy()\n",
    "\n",
    "    optimized_df[converted_int.columns] = converted_int\n",
    "    optimized_df[converted_float.columns] = converted_float\n",
    "\n",
    "    mem_df = float(mem_usage(df)[:-3])\n",
    "    mem_op_df = float(mem_usage(optimized_df)[:-3])\n",
    "    if mem_df<=mem_op_df:\n",
    "        print('Memory increased, returning original')\n",
    "        return df\n",
    "    \n",
    "    print(mem_df)\n",
    "    print(mem_op_df)\n",
    "    \n",
    "    return optimized_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108.32 MB\n",
      "60.93 MB\n",
      "54.16 MB\n",
      "54.16 MB\n",
      "1435.2\n",
      "1387.81\n",
      "77.42 MB\n",
      "43.55 MB\n",
      "38.71 MB\n",
      "38.71 MB\n",
      "1025.85\n",
      "991.98\n",
      "92.86 MB\n",
      "52.23 MB\n",
      "46.43 MB\n",
      "46.43 MB\n",
      "986.64\n",
      "946.01\n",
      "136.69 MB\n",
      "76.89 MB\n",
      "68.34 MB\n",
      "68.34 MB\n",
      "1811.11\n",
      "1751.31\n"
     ]
    }
   ],
   "source": [
    "dt_zps = optimize_df(dt_zps.drop_duplicates(inplace=False))\n",
    "dt_ois = optimize_df(dt_ois.drop_duplicates(inplace=False))\n",
    "dt_sps = optimize_df(dt_sps.drop_duplicates(inplace=False))\n",
    "dt_hot = optimize_df(dt_hot.drop_duplicates(inplace=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dt_ois['MAG'] = dt_ois['MAG_ISO'] + 4.990187644958496\n",
    "dt_zps['MAG'] = dt_zps['MAG_ISO'] -0.32352542877197266\n",
    "dt_hot['MAG'] = dt_hot['MAG_ISO'] + 5.040318489074707\n",
    "dt_sps['MAG'] = -2.5*np.log10(dt_sps['cflux']) + 16.995157469891133"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dt_ois['MU'] = dt_ois.MAG/(dt_ois.A_IMAGE*dt_ois.B_IMAGE)\n",
    "dt_zps['MU'] = dt_zps.MAG/(dt_zps.A_IMAGE*dt_zps.B_IMAGE)\n",
    "dt_hot['MU'] = dt_hot.MAG/(dt_hot.A_IMAGE*dt_hot.B_IMAGE)\n",
    "dt_sps['MU'] = dt_sps.MAG/(dt_sps.a*dt_sps.b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dt_ois['SN'] = dt_ois.FLUX_APER/dt_ois.FLUXERR_APER\n",
    "dt_zps['SN'] = dt_zps.FLUX_APER/dt_zps.FLUXERR_APER\n",
    "dt_hot['SN'] = dt_hot.FLUX_APER/dt_hot.FLUXERR_APER\n",
    "dt_sps['SN'] = dt_sps.cflux/np.sqrt(dt_sps.cflux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dt_ois.IS_REAL = dt_ois.IS_REAL.astype(int)\n",
    "dt_zps.IS_REAL = dt_zps.IS_REAL.astype(int)\n",
    "dt_hot.IS_REAL = dt_hot.IS_REAL.astype(int)\n",
    "dt_sps.IS_REAL = dt_sps.IS_REAL.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_samples = 450000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d_ois = dt_ois.sample(n_samples)\n",
    "d_zps = dt_zps.sample(n_samples)\n",
    "d_hot = dt_hot.sample(n_samples)\n",
    "d_sps = dt_sps.sample(n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_sps = d_sps['IS_REAL']\n",
    "Y_ois = d_ois['IS_REAL']\n",
    "Y_zps = d_zps['IS_REAL']\n",
    "Y_hot = d_hot['IS_REAL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d_ois = d_ois[[ u'FLUX_ISO', u'FLUXERR_ISO', u'MAG_ISO',\n",
    "       u'MAGERR_ISO', u'FLUX_APER', u'FLUXERR_APER', u'MAG_APER',\n",
    "       u'MAGERR_APER', u'FLUX_AUTO', u'FLUXERR_AUTO', u'MAG_AUTO',\n",
    "       u'MAGERR_AUTO', u'BACKGROUND', u'THRESHOLD', u'FLUX_MAX', u'X2_IMAGE', u'Y2_IMAGE',\n",
    "       u'XY_IMAGE', u'CXX_IMAGE', u'CYY_IMAGE', u'CXY_IMAGE', u'A_IMAGE',\n",
    "       u'B_IMAGE', u'THETA_IMAGE', u'MU_MAX', u'FLAGS', u'FWHM_IMAGE',\n",
    "       u'ELONGATION', u'ELLIPTICITY', u'CLASS_STAR', u'DELTAX', u'DELTAY',\n",
    "       u'RATIO', u'ROUNDNESS', u'PEAK_CENTROID', 'MAG', 'MU', 'SN']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "corr = d_ois.corr()\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.zeros_like(corr, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "corr_plot = sns.heatmap(corr, mask=mask, cmap='RdBu', center=0,\n",
    "                square=True, linewidths=.2, cbar_kws={\"shrink\": .5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d_zps = d_zps[[ u'FLUX_ISO', u'FLUXERR_ISO', u'MAG_ISO',\n",
    "       u'MAGERR_ISO', u'FLUX_APER', u'FLUXERR_APER', u'MAG_APER',\n",
    "       u'MAGERR_APER', u'FLUX_AUTO', u'FLUXERR_AUTO', u'MAG_AUTO',\n",
    "       u'MAGERR_AUTO', u'BACKGROUND', u'THRESHOLD', u'FLUX_MAX', u'X2_IMAGE', u'Y2_IMAGE',\n",
    "       u'XY_IMAGE', u'CXX_IMAGE', u'CYY_IMAGE', u'CXY_IMAGE', u'A_IMAGE',\n",
    "       u'B_IMAGE', u'THETA_IMAGE', u'MU_MAX', u'FLAGS', u'FWHM_IMAGE',\n",
    "       u'ELONGATION', u'ELLIPTICITY', u'CLASS_STAR', u'DELTAX', u'DELTAY',\n",
    "       u'RATIO', u'ROUNDNESS', u'PEAK_CENTROID', 'MAG', 'MU', 'SN']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corr = d_zps.corr()\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.zeros_like(corr, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "corr_plot = sns.heatmap(corr, mask=mask, cmap='RdBu', center=0,\n",
    "                square=True, linewidths=.2, cbar_kws={\"shrink\": .5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d_hot = d_hot[[ u'FLUX_ISO', u'FLUXERR_ISO', u'MAG_ISO',\n",
    "       u'MAGERR_ISO', u'FLUX_APER', u'FLUXERR_APER', u'MAG_APER',\n",
    "       u'MAGERR_APER', u'FLUX_AUTO', u'FLUXERR_AUTO', u'MAG_AUTO',\n",
    "       u'MAGERR_AUTO', u'BACKGROUND', u'THRESHOLD', u'FLUX_MAX', u'X2_IMAGE', u'Y2_IMAGE',\n",
    "       u'XY_IMAGE', u'CXX_IMAGE', u'CYY_IMAGE', u'CXY_IMAGE', u'A_IMAGE',\n",
    "       u'B_IMAGE', u'THETA_IMAGE', u'MU_MAX', u'FLAGS', u'FWHM_IMAGE',\n",
    "       u'ELONGATION', u'ELLIPTICITY', u'CLASS_STAR', u'DELTAX', u'DELTAY',\n",
    "       u'RATIO', u'ROUNDNESS', u'PEAK_CENTROID', 'MAG', 'MU', 'SN']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corr = d_hot.corr()\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.zeros_like(corr, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "corr_plot = sns.heatmap(corr, mask=mask, cmap='RdBu', center=0,\n",
    "                square=True, linewidths=.2, cbar_kws={\"shrink\": .5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'thresh', 'npix', 'tnpix', 'xmin_col', 'xmax_col', 'ymin', 'ymax',\n",
       "       'x', 'y', 'x2', 'y2', 'xy', 'errx2', 'erry2', 'errxy', 'a', 'b',\n",
       "       'theta', 'cxx', 'cyy', 'cxy', 'cflux', 'flux', 'cpeak', 'peak',\n",
       "       'xcpeak', 'ycpeak', 'xpeak', 'ypeak', 'flag', 'DELTAX', 'DELTAY',\n",
       "       'RATIO', 'ROUNDNESS', 'PEAK_CENTROID', 'IS_REAL', 'image_id', 'sim_mag',\n",
       "       'sim_id', 'MAG', 'MU', 'SN'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_sps.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d_sps = d_sps[[u'thresh', u'npix', u'tnpix', u'xmin_col', u'xmax_col', u'ymin', u'ymax', u'x', u'y', u'x2', u'y2',\n",
    "                  u'xy', u'errx2', u'erry2', u'errxy', u'a', u'b', u'theta', u'cxx', u'cyy', u'cxy', u'cflux',          u'flux',\n",
    "               u'cpeak', u'peak', u'xcpeak', u'ycpeak', u'xpeak', u'ypeak', u'flag', u'DELTAX',\n",
    "              u'DELTAY', u'RATIO', u'ROUNDNESS', u'PEAK_CENTROID', u'MAG', u'MU', u'SN']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corr = d_sps.corr()\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.zeros_like(corr, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "corr_plot = sns.heatmap(corr, mask=mask, cmap='RdBu', center=0,\n",
    "                square=True, linewidths=.2, cbar_kws={\"shrink\": .5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_zps = d_zps.values\n",
    "X_ois = d_ois.values\n",
    "X_hot = d_hot.values\n",
    "X_sps = d_sps.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler_ois = preprocessing.StandardScaler().fit(X_ois)\n",
    "scaler_zps = preprocessing.StandardScaler().fit(X_zps)\n",
    "scaler_hot = preprocessing.StandardScaler().fit(X_hot)\n",
    "scaler_sps = preprocessing.StandardScaler().fit(X_sps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_ois_scaled = scaler_ois.transform(X_ois)\n",
    "X_zps_scaled = scaler_zps.transform(X_zps)\n",
    "X_hot_scaled = scaler_hot.transform(X_hot)\n",
    "X_sps_scaled = scaler_sps.transform(X_sps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def importance_forest(X, y, forest=None, cols=None, method=None):\n",
    "    if forest is None:\n",
    "        forest = ExtraTreesClassifier(n_estimators=250,\n",
    "                                      random_state=0)\n",
    "    forest.fit(X, y)\n",
    "    importances = forest.feature_importances_\n",
    "    std = np.std([tree.feature_importances_ for tree in forest.estimators_],\n",
    "                 axis=0)\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    #print indices \n",
    "    #print importances\n",
    "    #print cols\n",
    "    # Print the feature ranking\n",
    "    #print(\"Feature ranking:\")\n",
    "\n",
    "    # Plot the feature importances of the forest\n",
    "    #plt.figure(figsize=(6, 6))\n",
    "    plt.title(\"{}\".format(method))\n",
    "    plt.barh(range(X.shape[1])[0:8], importances[indices][0:8], \n",
    "           color=\"r\", xerr=std[indices][0:8], align=\"center\")\n",
    "    if cols is not None:\n",
    "        plt.yticks(range(X.shape[1])[0:8], cols[indices-1][0:8], rotation='horizontal', fontsize=10)\n",
    "    else:\n",
    "        plt.yticks(range(X.shape[1]), indices)\n",
    "    #plt.ylim([-1, X.shape[1]])\n",
    "    plt.xlim(0, np.max(importances)+np.max(std))\n",
    "    ax = plt.gca()\n",
    "    ax.invert_yaxis() \n",
    "    #plt.show()\n",
    "    return [(cols[indices[f]-1], importances[indices[f]]) for f in range(X.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 14))\n",
    "plt.subplot(411)\n",
    "ois_importance = importance_forest(X_ois_scaled, Y_ois, \n",
    "                                   forest=RandomForestClassifier(n_estimators=400, random_state=0, n_jobs=-1), \n",
    "                                   cols=d_ois.columns, method='Bramich')\n",
    "plt.xlim(0, 0.3)\n",
    "plt.subplot(412)\n",
    "zps_importance = importance_forest(X_zps_scaled, Y_zps, \n",
    "                                   forest=RandomForestClassifier(n_estimators=400, random_state=0, n_jobs=-1), \n",
    "                                   cols=d_zps.columns, method='Zackay')\n",
    "plt.xlim(0, 0.3)\n",
    "plt.subplot(413)\n",
    "hot_importance = importance_forest(X_hot_scaled, Y_hot, \n",
    "                                   forest=RandomForestClassifier(n_estimators=400, random_state=0, n_jobs=-1), \n",
    "                                   cols=d_hot.columns, method='Alard-Lupton')\n",
    "plt.xlim(0, 0.3)\n",
    "plt.subplot(414)\n",
    "sps_importance = importance_forest(X_sps_scaled, Y_sps, \n",
    "                                   forest=RandomForestClassifier(n_estimators=400, random_state=0, n_jobs=-1), \n",
    "                                   cols=d_sps.columns, method='Scorr')\n",
    "plt.xlim(0, 0.3)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def full_importance_forest(X, y, forest=None, cols=None, method=None):\n",
    "    if forest is None:\n",
    "        forest = ExtraTreesClassifier(n_estimators=250,\n",
    "                                  random_state=0)\n",
    "    forest.fit(X, y)\n",
    "    importances = forest.feature_importances_\n",
    "    std = np.std([tree.feature_importances_ for tree in forest.estimators_],\n",
    "                 axis=0)\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    \n",
    "    return [indices, importances, cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ois_importance = full_importance_forest(X_ois_scaled, Y_ois, \n",
    "                                        RandomForestClassifier(n_estimators=400, random_state=0, n_jobs=-1),\n",
    "                                        cols=d_ois.columns, method='Bramich')\n",
    "zps_importance = full_importance_forest(X_zps_scaled, Y_zps, \n",
    "                                        ExtraTreesClassifier(n_estimators=400, random_state=0, n_jobs=-1), \n",
    "                                        cols=d_zps.columns, method='Zackay')\n",
    "hot_importance = full_importance_forest(X_hot_scaled, Y_hot, \n",
    "                                        ExtraTreesClassifier(n_estimators=400, random_state=0, n_jobs=-1), \n",
    "                                        cols=d_hot.columns, method='Alard-Lupton')\n",
    "sps_importance = full_importance_forest(X_sps_scaled, Y_sps, \n",
    "                                        ExtraTreesClassifier(n_estimators=400, random_state=0, n_jobs=-1), \n",
    "                                        cols=d_sps.columns, method='Scorr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([25, 33, 27, 28, 12, 26, 34, 11, 37, 10,  4,  7,  8,  6, 32, 21,  5,\n",
       "        14, 24, 13,  9,  3, 22,  1,  2,  0, 36, 35, 19, 18, 29, 15, 16, 17,\n",
       "        20, 23, 31, 30]),\n",
       " array([0.01040447, 0.01209101, 0.0104584 , 0.01261871, 0.02575726,\n",
       "        0.0191852 , 0.02311525, 0.02554714, 0.02367576, 0.01525822,\n",
       "        0.02885588, 0.03263868, 0.05790918, 0.01751584, 0.0189153 ,\n",
       "        0.00636619, 0.00622114, 0.0059434 , 0.00897968, 0.0090288 ,\n",
       "        0.00587671, 0.02029406, 0.01245265, 0.00490387, 0.01814478,\n",
       "        0.10435857, 0.05776723, 0.08794921, 0.08761053, 0.00820519,\n",
       "        0.00341615, 0.00370724, 0.02102285, 0.10114471, 0.04312008,\n",
       "        0.01002345, 0.01005345, 0.02946378]),\n",
       " Index(['FLUX_ISO', 'FLUXERR_ISO', 'MAG_ISO', 'MAGERR_ISO', 'FLUX_APER',\n",
       "        'FLUXERR_APER', 'MAG_APER', 'MAGERR_APER', 'FLUX_AUTO', 'FLUXERR_AUTO',\n",
       "        'MAG_AUTO', 'MAGERR_AUTO', 'BACKGROUND', 'THRESHOLD', 'FLUX_MAX',\n",
       "        'X2_IMAGE', 'Y2_IMAGE', 'XY_IMAGE', 'CXX_IMAGE', 'CYY_IMAGE',\n",
       "        'CXY_IMAGE', 'A_IMAGE', 'B_IMAGE', 'THETA_IMAGE', 'MU_MAX', 'FLAGS',\n",
       "        'FWHM_IMAGE', 'ELONGATION', 'ELLIPTICITY', 'CLASS_STAR', 'DELTAX',\n",
       "        'DELTAY', 'RATIO', 'ROUNDNESS', 'PEAK_CENTROID', 'MAG', 'MU', 'SN'],\n",
       "       dtype='object')]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ois_importance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ois_importance[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mat = np.empty((3, 38))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mat[0, :] = ois_importance[1]\n",
    "mat[1, :] = zps_importance[1]\n",
    "mat[2, :] = sps_importance[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "names  = []\n",
    "for aname in ois_importance[2]:\n",
    "    names.append(aname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(3, 12))\n",
    "sns.heatmap(mat.T, cmap='gray_r')\n",
    "\n",
    "plt.yticks(np.arange(38)+0.5,names, rotation='horizontal')\n",
    "plt.xticks(np.arange(3)+0.5, ['Bramich', 'Zackay', 'A.-Lupton'])\n",
    "#plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['thresh', 'npix', 'tnpix', 'xmin_col', 'xmax_col', 'ymin', 'ymax', 'x',\n",
       "       'y', 'x2', 'y2', 'xy', 'errx2', 'erry2', 'errxy', 'a', 'b', 'theta',\n",
       "       'cxx', 'cyy', 'cxy', 'cflux', 'flux', 'cpeak', 'peak', 'xcpeak',\n",
       "       'ycpeak', 'xpeak', 'ypeak', 'flag', 'DELTAX', 'DELTAY', 'RATIO',\n",
       "       'ROUNDNESS', 'PEAK_CENTROID', 'MAG', 'MU', 'SN'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sps_importance[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importances with permutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def importance_perm(X, y, forest=None, cols=None, method=None):\n",
    "    \n",
    "    X = pd.DataFrame(X, columns=cols)\n",
    "    y = pd.DataFrame(y)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)\n",
    "    \n",
    "    if forest is None:\n",
    "        forest = RandomForestClassifier(n_estimators=250, random_state=33, n_jobs=-1)\n",
    "    \n",
    "    X_train['Random'] = np.random.random(size=len(X_train))\n",
    "    X_test['Random'] = np.random.random(size=len(X_test))\n",
    "    \n",
    "    forest.fit(X_train, y_train)\n",
    "    imp = importances(forest, X_test, y_test) # permutation\n",
    "    return imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bos0109/.conda/envs/benv3/lib/python3.6/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "ois_importance = importance_perm(X_ois_scaled, Y_ois, \n",
    "                                 RandomForestClassifier(n_estimators=400, random_state=0, n_jobs=-1), \n",
    "                                 cols=d_ois.columns, method='Bramich')\n",
    "zps_importance = importance_perm(X_zps_scaled, Y_zps, \n",
    "                                 RandomForestClassifier(n_estimators=400, random_state=0, n_jobs=-1), \n",
    "                                 cols=d_zps.columns, method='Zackay')\n",
    "hot_importance = importance_perm(X_hot_scaled, Y_hot, \n",
    "                                 RandomForestClassifier(n_estimators=400, random_state=0, n_jobs=-1), \n",
    "                                 cols=d_hot.columns, method='Alard-Lupton')\n",
    "sps_importance = importance_perm(X_sps_scaled, Y_sps, \n",
    "                                 RandomForestClassifier(n_estimators=400, random_state=0, n_jobs=-1), \n",
    "                                 cols=d_sps.columns, method='Scorr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['thresh', 'npix', 'tnpix', 'xmin_col', 'xmax_col', 'ymin', 'ymax', 'x',\n",
       "       'y', 'x2', 'y2', 'xy', 'errx2', 'erry2', 'errxy', 'a', 'b', 'theta',\n",
       "       'cxx', 'cyy', 'cxy', 'cflux', 'flux', 'cpeak', 'peak', 'xcpeak',\n",
       "       'ycpeak', 'xpeak', 'ypeak', 'flag', 'DELTAX', 'DELTAY', 'RATIO',\n",
       "       'ROUNDNESS', 'PEAK_CENTROID', 'MAG', 'MU', 'SN'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_sps.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transl = {u'thresh': u'THRESHOLD', \n",
    "          u'peak': u'FLUX_MAX',\n",
    "          u'x2': u'X2_IMAGE', \n",
    "          u'y2': u'Y2_IMAGE',\n",
    "          u'xy': u'XY_IMAGE',\n",
    "          u'a':u'A_IMAGE',\n",
    "          u'b':u'B_IMAGE',\n",
    "          u'theta':u'THETA_IMAGE',\n",
    "          u'cxx':u'CXX_IMAGE',\n",
    "          u'cyy':u'CYY_IMAGE',\n",
    "          u'cxy':u'CXY_IMAGE',\n",
    "          u'cflux':u'FLUX_ISO',\n",
    "          u'flux':u'FLUX_APER',\n",
    "          u'flag': u'FLAGS',\n",
    "          u'DELTAX': u'DELTAX',\n",
    "          u'DELTAY': u'DELTAY',\n",
    "          u'RATIO': u'RATIO',\n",
    "          u'ROUNDNESS': u'ROUNDNESS',\n",
    "          u'PEAK_CENTROID': u'PEAK_CENTROID',\n",
    "          u'MAG': u'MAG',\n",
    "          u'MU': u'MU',\n",
    "          u'SN': u'SN'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "detransl = {v: k for k, v in transl.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "complement = []\n",
    "for v in d_sps.columns:\n",
    "    if v not in detransl.values():\n",
    "        complement.append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sps_importance = sps_importance.rename(index=transl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = d_ois.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newcols = list(cols.values)\n",
    "newcols.extend(complement)\n",
    "newcols.extend(['Random'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bos0109/.conda/envs/benv3/lib/python3.6/site-packages/ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "m = pd.concat([ois_importance, zps_importance, hot_importance, sps_importance], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = m.reindex(newcols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(3, 12))\n",
    "sns.heatmap(m, robust=True, cmap='gray_r')\n",
    "\n",
    "plt.yticks(np.arange(len(m))+0.5, rotation='horizontal')\n",
    "plt.xticks(np.arange(4)+0.5, ['Bramich', 'Zackay', 'A.-Lupton', 'Scorr'], rotation=45)\n",
    "#plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying Stratified K-Fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def importance_perm_kfold(X, y, forest=None, cols=None, method=None, nfolds=10):\n",
    "    skf = StratifiedKFold(n_splits=nfolds)\n",
    "    imp = []\n",
    "\n",
    "    for train, test in skf.split(X, y):      \n",
    "        X_train = pd.DataFrame(X[train], columns=cols)\n",
    "        X_test = pd.DataFrame(X[test], columns=cols)\n",
    "        y_train = pd.DataFrame(y[train])\n",
    "        y_test = pd.DataFrame(y[test])\n",
    "        \n",
    "        if forest is None:\n",
    "            forest = RandomForestClassifier(n_estimators=250, random_state=33, n_jobs=-1)\n",
    "\n",
    "        X_train['Random'] = np.random.random(size=len(X_train))\n",
    "        X_test['Random'] = np.random.random(size=len(X_test))\n",
    "\n",
    "        forest.fit(X_train, y_train)\n",
    "        imp.append(importances(forest, X_test, y_test)) # permutation\n",
    "    #imp = pd.concat(imp, axis=1)\n",
    "    return imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "ois_importance = importance_perm_kfold(X_ois_scaled, Y_ois.values.ravel(), \n",
    "                                       RandomForestClassifier(n_estimators=400, random_state=0, n_jobs=-1), \n",
    "                                       cols=d_ois.columns, method='Bramich')\n",
    "zps_importance = importance_perm_kfold(X_zps_scaled, Y_zps.values.ravel(), \n",
    "                                       RandomForestClassifier(n_estimators=400, random_state=0, n_jobs=-1), \n",
    "                                       cols=d_zps.columns, method='Zackay')\n",
    "hot_importance = importance_perm_kfold(X_hot_scaled, Y_hot.values.ravel(), \n",
    "                                       RandomForestClassifier(n_estimators=400, random_state=0, n_jobs=-1), \n",
    "                                       cols=d_hot.columns, method='Alard-Lupton')\n",
    "sps_importance = importance_perm_kfold(X_sps_scaled, Y_sps.values.ravel(), \n",
    "                                       RandomForestClassifier(n_estimators=400, random_state=0, n_jobs=-1), \n",
    "                                       cols=d_sps.columns, method='Scorr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sps_newimp = []\n",
    "for animp in sps_importance:\n",
    "    sps_newimp.append(animp.rename(index=transl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bos0109/.conda/envs/benv3/lib/python3.6/site-packages/ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/bos0109/.conda/envs/benv3/lib/python3.6/site-packages/ipykernel_launcher.py:2: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \n",
      "/home/bos0109/.conda/envs/benv3/lib/python3.6/site-packages/ipykernel_launcher.py:3: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/bos0109/.conda/envs/benv3/lib/python3.6/site-packages/ipykernel_launcher.py:4: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "res_ois = pd.concat(ois_importance, axis=1)\n",
    "res_zps = pd.concat(zps_importance, axis=1)\n",
    "res_hot = pd.concat(hot_importance, axis=1)\n",
    "res_sps = pd.concat(sps_newimp, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res_ois.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bos0109/.conda/envs/benv3/lib/python3.6/site-packages/ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "m = pd.concat([res_ois.mean(axis=1), res_zps.mean(axis=1), res_hot.mean(axis=1), res_sps.mean(axis=1)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m = m.reindex(newcols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = pd.concat([res_ois.std(axis=1), res_zps.std(axis=1), res_hot.std(axis=1), res_sps.std(axis=1)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = s.reindex(newcols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    m[i] = m[i] - m[i]['Random']\n",
    "    m[i] = m[i]/np.max(m[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0   -0.005367\n",
       " 1   -0.000409\n",
       " 2   -0.008463\n",
       " 3   -0.003410\n",
       " dtype: float64, 0    1.0\n",
       " 1    1.0\n",
       " 2    1.0\n",
       " 3    1.0\n",
       " dtype: float64)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(m), np.max(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m2 = m.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 12))\n",
    "plt.imshow(m2.fillna(0).as_matrix(), vmin=0, vmax=1., cmap='gray_r', aspect='auto')\n",
    "plt.yticks(np.arange(len(m)), m.index, rotation='horizontal')\n",
    "plt.xticks(np.arange(4)+0.5, ['Bramich', 'Zackay', 'A.-Lupton', 'Scorr'], rotation=45)\n",
    "plt.grid()\n",
    "plt.colorbar()\n",
    "plt.savefig('./feature_heatmap_simdata.svg',  bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 12))\n",
    "plt.imshow(m2.fillna(0).as_matrix(), vmin=0, vmax=1., cmap='viridis', aspect='auto')\n",
    "plt.yticks(np.arange(len(m)), m.index, rotation='horizontal')\n",
    "plt.xticks(np.arange(4)+0.5, ['Bramich', 'Zackay', 'A.-Lupton', 'Scorr'], rotation=45)\n",
    "plt.grid()\n",
    "plt.colorbar()\n",
    "plt.savefig('./feature_heatmap_simdata_color.svg',  bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(3, 12))\n",
    "sns.heatmap(m, robust=True, cmap='Greys_r')\n",
    "\n",
    "plt.yticks(np.arange(len(m))+0.5, rotation='horizontal')\n",
    "plt.xticks(np.arange(4)+0.5, ['Bramich', 'Zackay', 'A.-Lupton', 'Scorr'], rotation=45)\n",
    "#plt.colorbar()\n",
    "plt.savefig('./feature_heatmap_simdata.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(3, 12))\n",
    "sns.heatmap(s, robust=True, cmap='RdBu')\n",
    "\n",
    "plt.yticks(np.arange(len(s))+0.5, rotation='horizontal')\n",
    "plt.xticks(np.arange(4)+0.5, ['Bramich', 'Zackay', 'A.-Lupton', 'Scorr'], rotation=45)\n",
    "#plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.subplot(221)\n",
    "selected_ois = m[0][m[0] > m.loc['Random'][0]]\n",
    "plt.bar(selected_ois.index, selected_ois.values)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.ylabel('Importance Bramich')\n",
    "#plt.xticks(np.arange(len(selected_ois.index)), selected_ois.index, rotation=45)\n",
    "\n",
    "plt.subplot(222)\n",
    "selected_zps = m[1][m[1] > m.loc['Random'][1]]\n",
    "plt.bar(selected_zps.index, selected_zps.values)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.ylabel('Importance Zackay')\n",
    "\n",
    "plt.subplot(223)\n",
    "selected_hot = m[2][m[2] > m.loc['Random'][2]]\n",
    "plt.bar(selected_hot.index, selected_hot.values)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.ylabel('Importance Alard-Lupton')\n",
    "\n",
    "plt.subplot(224)\n",
    "selected_sps = m[3][m[3] > m.loc['Random'][3]]\n",
    "plt.bar(selected_sps.index, selected_sps.values)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.ylabel('Importance Scorr')\n",
    "\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
